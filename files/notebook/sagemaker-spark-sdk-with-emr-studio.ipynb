{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMR Notebook SageMaker Custom Abalone Ring Estimator\n",
    "\n",
    "1. [Setup](#Setup)\n",
    "2. [Load the Data](#Load-the-Data)\n",
    "3. [Train the Model](#Train-the-Model)\n",
    "4. [Inference Results](#Inference-Results)\n",
    "5. [Wrap-Up](#Wrap-Up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:02:10.768350Z",
     "iopub.status.busy": "2022-03-14T17:02:10.768081Z",
     "iopub.status.idle": "2022-03-14T17:02:37.440688Z",
     "shell.execute_reply": "2022-03-14T17:02:37.440035Z",
     "shell.execute_reply.started": "2022-03-14T17:02:10.768316Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9711f73165c64458bbb0456b3ca672da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>1</td><td>application_1646957004110_0003</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-46-137.ec2.internal:20888/proxy/application_1646957004110_0003/\" class=\"emr-proxy-link\" emr-resource=\"j-RBCN5UZU9CZS\n",
       "\" application-id=\"application_1646957004110_0003\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-36-61.ec2.internal:8042/node/containerlogs/container_1646957004110_0003_01_000001/livy\" >Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary user parameters are entered."
     ]
    }
   ],
   "source": [
    "# *****DEFINE USER SPECIFIC PARAMETERS******\n",
    "region = 'us-east-1'\n",
    "sagemaker_execution_role = 'arn:aws:iam::620614497509:role/SagemakerExecutionRole'\n",
    "\n",
    "#The number of EMR nodes to process the data.\n",
    "num_workers = 12\n",
    "\n",
    "# The location of the dataset we will be using. \n",
    "source_bucket = 'ee-assets-prod-us-east-1'\n",
    "source_key = 'modules/8560b4bd6942403b9fe3291928df2453/v1/data/abalone.csv'\n",
    "\n",
    "if (region and source_bucket and sagemaker_execution_role and num_workers):\n",
    "    print('All necessary user parameters are entered.')\n",
    "else:\n",
    "    print('Please check to make sure you entered all default parameters!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each EMR notebook is launched with its own Spark context (variable sc). A Spark Context is the entry point for communication with Spark. First you need to install the Python packages that you'll use throughout the notebook. EMR notebooks come with a default set of libraries for data processing. You can see which libraries are installed on the notebook by calling the Spark Context's list_packages() function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:02:57.976437Z",
     "iopub.status.busy": "2022-03-14T17:02:57.976175Z",
     "iopub.status.idle": "2022-03-14T17:02:58.749129Z",
     "shell.execute_reply": "2022-03-14T17:02:58.748547Z",
     "shell.execute_reply.started": "2022-03-14T17:02:57.976406Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2282b6d6db6f41b8824ff868580e5929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-cfn-bootstrap (2.0)\n",
      "beautifulsoup4 (4.9.3)\n",
      "boto (2.49.0)\n",
      "click (8.0.1)\n",
      "docutils (0.14)\n",
      "jmespath (0.10.0)\n",
      "joblib (1.0.1)\n",
      "lockfile (0.11.0)\n",
      "lxml (4.6.3)\n",
      "mysqlclient (1.4.2)\n",
      "nltk (3.6.2)\n",
      "nose (1.3.4)\n",
      "numpy (1.16.5)\n",
      "pip (9.0.1)\n",
      "py-dateutil (2.2)\n",
      "pystache (0.5.4)\n",
      "python-daemon (2.2.3)\n",
      "python37-sagemaker-pyspark (1.4.1)\n",
      "pytz (2021.1)\n",
      "PyYAML (5.4.1)\n",
      "regex (2021.8.3)\n",
      "setuptools (28.8.0)\n",
      "simplejson (3.2.0)\n",
      "six (1.13.0)\n",
      "tqdm (4.62.1)\n",
      "wheel (0.29.0)\n",
      "windmill (1.6)\n",
      "\n",
      "DEPRECATION: The default format will switch to columns in the future. You can use --format=(legacy|columns) (or define a format=(legacy|columns) in your pip.conf under the [list] section) to disable this warning.\n",
      "You are using pip version 9.0.1, however version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command."
     ]
    }
   ],
   "source": [
    "sc.list_packages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To comunicate with SageMaker you need to install notebook scoped libraries. These libraries are available only during the notebook session. After the session ends, the libraries are deleted. \n",
    "\n",
    "We install [boto3 (the AWS Python 3 SDK)](https://aws.amazon.com/sdk-for-python/) and the [high level SageMaker SDK](https://sagemaker.readthedocs.io/en/stable/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:02.224438Z",
     "iopub.status.busy": "2022-03-14T17:03:02.224179Z",
     "iopub.status.idle": "2022-03-14T17:03:25.605914Z",
     "shell.execute_reply": "2022-03-14T17:03:25.605198Z",
     "shell.execute_reply.started": "2022-03-14T17:03:02.224408Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762e46a03d1843e3b87e7588032247a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3==1.16.9\n",
      "  Using cached https://files.pythonhosted.org/packages/e3/99/3979b617c0cbb3d7260cd3357b4a06edaa91073dd252687b7502f6678bb8/boto3-1.16.9-py2.py3-none-any.whl\n",
      "Collecting botocore<1.20.0,>=1.19.9 (from boto3==1.16.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/05/0a955f0c92bec7da076fbbc73926dfb13fab8e2b88de7f8eb17c443f28f0/botocore-1.19.63-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3==1.16.9)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3==1.16.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/00/89/0cb4e92c239e6425b9b0035227b8cdf9d3d098a5c9e95632c3815df63a09/s3transfer-0.3.7-py2.py3-none-any.whl\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore<1.20.0,>=1.19.9->boto3==1.16.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/7a/87837f39d0296e723bb9b62bbb257d0355c7f6128853c78955f57342a56d/python_dateutil-2.8.2-py2.py3-none-any.whl\n",
      "Collecting urllib3<1.27,>=1.25.4; python_version != \"3.4\" (from botocore<1.20.0,>=1.19.9->boto3==1.16.9)\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/b8/f5a25b22e803f0578e668daa33ba3701bb37858ec80e08a150bd7d2cf1b1/urllib3-1.26.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.9->boto3==1.16.9)\n",
      "Installing collected packages: python-dateutil, urllib3, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.16.9 botocore-1.19.63 python-dateutil-2.8.2 s3transfer-0.3.7 urllib3-1.26.8\n",
      "\n",
      "Collecting sagemaker==2.16.1\n",
      "Collecting importlib-metadata>=1.4.0 (from sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/f2/c48787ca7d1e20daa185e1b6b2d4e16acd2fb5e0320bc50ffc89b91fa4d7/importlib_metadata-4.11.3-py3-none-any.whl\n",
      "Collecting protobuf>=3.1 (from sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/1c/f18d97fc479b4fb6f72bbb0e41188575362e3bbd31014cf294ef0fdec8bf/protobuf-3.19.4-py2.py3-none-any.whl\n",
      "Collecting smdebug-rulesconfig==0.1.5 (from sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/3e/d9/10f5d4e1992575b704a9a0d0af1e962e31c6409ab414f686fdc2e2d42787/smdebug_rulesconfig-0.1.5-py2.py3-none-any.whl\n",
      "Collecting protobuf3-to-dict>=0.1.5 (from sagemaker==2.16.1)\n",
      "Collecting packaging>=20.0 (from sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl\n",
      "Requirement already satisfied: boto3>=1.14.12 in /mnt/tmp/1647277354157-0/lib/python3.7/site-packages (from sagemaker==2.16.1)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib64/python3.7/site-packages (from sagemaker==2.16.1)\n",
      "Collecting google-pasta (from sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\" (from importlib-metadata>=1.4.0->sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/45/6b/44f7f8f1e110027cf88956b59f2fad776cca7e1704396d043f89effd3a0e/typing_extensions-4.1.1-py3-none-any.whl\n",
      "Collecting zipp>=0.5 (from importlib-metadata>=1.4.0->sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/52/c5/df7953fe6065185af5956265e3b16f13c2826c2b1ba23d43154f3af453bc/zipp-3.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker==2.16.1)\n",
      "Collecting pyparsing!=3.0.5,>=2.0.2 (from packaging>=20.0->sagemaker==2.16.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/80/c1/23fd82ad3121656b585351aba6c19761926bb0db2ebed9e4ff09a43a3fcc/pyparsing-3.0.7-py3-none-any.whl\n",
      "Requirement already satisfied: botocore<1.20.0,>=1.19.9 in /mnt/tmp/1647277354157-0/lib/python3.7/site-packages (from boto3>=1.14.12->sagemaker==2.16.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3>=1.14.12->sagemaker==2.16.1)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /mnt/tmp/1647277354157-0/lib/python3.7/site-packages (from boto3>=1.14.12->sagemaker==2.16.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /mnt/tmp/1647277354157-0/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.9->boto3>=1.14.12->sagemaker==2.16.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4; python_version != \"3.4\" in /mnt/tmp/1647277354157-0/lib/python3.7/site-packages (from botocore<1.20.0,>=1.19.9->boto3>=1.14.12->sagemaker==2.16.1)\n",
      "Installing collected packages: typing-extensions, zipp, importlib-metadata, protobuf, smdebug-rulesconfig, protobuf3-to-dict, pyparsing, packaging, google-pasta, sagemaker\n",
      "Successfully installed google-pasta-0.2.0 importlib-metadata-4.11.3 packaging-21.3 protobuf-3.19.4 protobuf3-to-dict-0.1.5 pyparsing-3.0.7 sagemaker-2.16.1 smdebug-rulesconfig-0.1.5 typing-extensions-4.1.1 zipp-3.7.0\n",
      "\n",
      "You are using pip version 9.0.1, however version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "\n",
      "You are using pip version 9.0.1, however version 22.0.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command."
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"boto3==1.16.9\");\n",
    "sc.install_pypi_package('sagemaker==2.16.1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:25.607146Z",
     "iopub.status.busy": "2022-03-14T17:03:25.606948Z",
     "iopub.status.idle": "2022-03-14T17:03:26.375385Z",
     "shell.execute_reply": "2022-03-14T17:03:26.374574Z",
     "shell.execute_reply.started": "2022-03-14T17:03:25.607118Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5752d17c4eb4f1ba03a6f274eff2770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A SageMaker session was initiated! You are using sagemaker-us-east-1-620614497509 as your S3 bucket for intermediate files."
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "boto_sess = boto3.Session(region_name=region)\n",
    "sage_sdk_session = sagemaker.Session(boto_session=boto_sess)\n",
    "bucket = sage_sdk_session.default_bucket()\n",
    "\n",
    "print('A SageMaker session was initiated! You are using {} as your S3 bucket for intermediate files.'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "We will use the public abalone data set from the [UC Irvine Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Abalone)\n",
    "to train and test a regression model.\n",
    "\n",
    "   Given in the dataset is the attribute name, attribute type, the measurement unit and a\n",
    "   brief description.  The number of rings is the value to predict: either\n",
    "   as a continuous value or as a classification problem.\n",
    "   \n",
    "   The age of an abalone is the number of rings in the shell + 1.5 years. Without a model researchers must cut through the abalone shell\n",
    "   and use a microscope to count the rings. Using a model to predict rings eliminates this time consuming process.\n",
    "\n",
    "\tName\t\t\tData Type\t\tMeas.\tDescription\n",
    "\t----\t\t\t---------\t\t-----\t-----------\n",
    "\tRings\t\t\tinteger\t\t\t\t\t+1.5 gives the age in years\n",
    "\tLength\t\t\tcontinuous\t\tmm\t\tLongest shell measurement\n",
    "\tDiameter\t\tcontinuous\t\tmm\t\tperpendicular to length\n",
    "\tHeight\t\t\tcontinuous\t\tmm\t\twith meat in shell\n",
    "\tWhole weight\tcontinuous\t\tgrams\twhole abalone\n",
    "\tShucked weight\tcontinuous\t\tgrams\tweight of meat\n",
    "\tViscera weight\tcontinuous\t\tgrams\tgut weight (after bleeding)\n",
    "\tShell weight\tcontinuous\t\tgrams\tafter being dried\n",
    "\tMale\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false\n",
    "\tFemale\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false\n",
    "\tInfant\t\t\tinteger\t\t\t1/0 \t1 encodes true, 0 false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to copy the public files to the S3 bucket in our account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:26.376985Z",
     "iopub.status.busy": "2022-03-14T17:03:26.376789Z",
     "iopub.status.idle": "2022-03-14T17:03:27.142567Z",
     "shell.execute_reply": "2022-03-14T17:03:27.141908Z",
     "shell.execute_reply.started": "2022-03-14T17:03:26.376956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea4fa58e1a8949b4963905ad3959e871",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3 = boto3.client('s3', region_name=region)\n",
    "\n",
    "# Local bucket S3 prefix to store the data under.\n",
    "local_key = 'data/abalone.csv'\n",
    "\n",
    "s3.copy(CopySource={'Bucket' : source_bucket,\n",
    "                    'Key' : source_key}, \n",
    "        Bucket=bucket, \n",
    "        Key=local_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:27.143877Z",
     "iopub.status.busy": "2022-03-14T17:03:27.143678Z",
     "iopub.status.idle": "2022-03-14T17:03:42.479329Z",
     "shell.execute_reply": "2022-03-14T17:03:42.478601Z",
     "shell.execute_reply.started": "2022-03-14T17:03:27.143849Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe8ca61cdf4c839d975ad23f3fe936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "|Rings|Length|Diameter|Height|Whole_weight|Shucked_weight|Viscera_weight|Shell_weight|Male|Female|Infant|\n",
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "|    9| 0.665|   0.505| 0.165|       1.349|        0.5985|        0.3175|        0.36|   0|     1|     0|\n",
      "|    7| 0.505|    0.39| 0.185|      0.6125|         0.267|         0.142|       0.172|   0|     0|     1|\n",
      "|   13| 0.575|   0.475|  0.17|       0.967|        0.3775|         0.284|       0.275|   0|     0|     1|\n",
      "|    9| 0.455|   0.355| 0.105|       0.372|         0.138|        0.0765|       0.135|   0|     0|     1|\n",
      "|   17|  0.52|   0.425| 0.155|      0.7735|         0.297|         0.123|       0.255|   1|     0|     0|\n",
      "+-----+------+--------+------+------------+--------------+--------------+------------+----+------+------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "# Read the dataset from S3 in to a Spark dataframe.\n",
    "abalone_data = spark.read.load(f's3://{bucket}/{local_key}', format='csv', inferSchema=True, header=True).repartition(num_workers)\n",
    "abalone_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is in Spark we can modify and enhance our data. As an example, including all four abalone weights may be unnecessary. What really matters may be the difference between the whole weight and the shell weight. Making such changes on large datasets can be done easily in Spark.\n",
    "\n",
    "Let's try adding a column that is the difference between whole weight and shell weight. Then remove the whole, shucked, weight, and shell weight columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:42.480399Z",
     "iopub.status.busy": "2022-03-14T17:03:42.480194Z",
     "iopub.status.idle": "2022-03-14T17:03:47.779277Z",
     "shell.execute_reply": "2022-03-14T17:03:47.778605Z",
     "shell.execute_reply.started": "2022-03-14T17:03:42.480370Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b601175e6b41519090a50980011ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+----+------+------+------------------+\n",
      "|Rings|Length|Diameter|Height|Male|Female|Infant| Difference_weight|\n",
      "+-----+------+--------+------+----+------+------+------------------+\n",
      "|   16|  0.74|     0.6| 0.195|   0|     1|     0|             1.264|\n",
      "|   13| 0.655|    0.52| 0.175|   0|     1|     0|             1.022|\n",
      "|    6| 0.385|    0.29| 0.095|   0|     0|     1|             0.226|\n",
      "|   23|   0.8|    0.63| 0.195|   0|     1|     0|1.9059999999999997|\n",
      "|   11|  0.63|    0.48|  0.16|   0|     1|     0|0.8840000000000001|\n",
      "+-----+------+--------+------+----+------+------+------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "abalone_data = abalone_data.withColumn('Difference_weight', abalone_data.Whole_weight - abalone_data.Shell_weight)\n",
    "abalone_data = abalone_data.drop('Whole_weight', 'Shucked_weight', 'Viscera_weight', 'Shell_weight')\n",
    "abalone_data.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:03:47.780338Z",
     "iopub.status.busy": "2022-03-14T17:03:47.780141Z",
     "iopub.status.idle": "2022-03-14T17:04:03.214699Z",
     "shell.execute_reply": "2022-03-14T17:04:03.214004Z",
     "shell.execute_reply.started": "2022-03-14T17:03:47.780309Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9972f1f97845f98e2e9ebb42e50d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset saved in csv format to s3://sagemaker-us-east-1-620614497509/train/!\n",
      "Testing dataset saved in csv format to s3://sagemaker-us-east-1-620614497509/test/!"
     ]
    }
   ],
   "source": [
    "# Split the dataframe in to training and validation data.\n",
    "# The training will be used to refine our model.\n",
    "# The test data will be used to measure the model's accuracy.\n",
    "train_data, test_data = abalone_data.randomSplit([.75,.25])\n",
    "\n",
    "s3_train = f's3://{bucket}/train/'\n",
    "s3_test = f's3://{bucket}/test/'\n",
    "data_format = 'csv'\n",
    "\n",
    "# Save the data in to S3 for training by SageMaker\n",
    "train_data.write.save(s3_train, format=data_format, mode='overwrite')\n",
    "test_data.write.save(s3_test, format=data_format, mode='overwrite')\n",
    "\n",
    "print(f'Training dataset saved in {data_format} format to {s3_train}!')\n",
    "print(f'Testing dataset saved in {data_format} format to {s3_test}!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "SageMaker contains several common built-in algorithms. For this lab you have the choice of using either the [LinearLearner](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html) or [XGBoost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html) built-in algorithms. Both are regression models that estimate the number of rings on the abalone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:04:03.215875Z",
     "iopub.status.busy": "2022-03-14T17:04:03.215675Z",
     "iopub.status.idle": "2022-03-14T17:04:03.275214Z",
     "shell.execute_reply": "2022-03-14T17:04:03.274614Z",
     "shell.execute_reply.started": "2022-03-14T17:04:03.215848Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5ab42ef8b546b1b57c6b80fea12d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SageMaker xgboost model will be used."
     ]
    }
   ],
   "source": [
    "# Uncomment the LinearLearner line to use the LinearLearner algorithm. \n",
    "model = 'xgboost'\n",
    "#model = 'linear-learner'\n",
    "\n",
    "print('The SageMaker {} model will be used.'.format(model))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following cell defines the hyperparameters for each algorithn. You may leave them as the defaults, but if you are interested you could try changing a few to see if it improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:04:03.277013Z",
     "iopub.status.busy": "2022-03-14T17:04:03.276746Z",
     "iopub.status.idle": "2022-03-14T17:04:03.336717Z",
     "shell.execute_reply": "2022-03-14T17:04:03.336140Z",
     "shell.execute_reply.started": "2022-03-14T17:04:03.276966Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b7eed9edb741bc8914f072d1503d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model parameters have been set!"
     ]
    }
   ],
   "source": [
    "# Set the regularization weights. Increasing these will reduce how closely the model fits to the training data.\n",
    "l1 = .25\n",
    "l2 = .25\n",
    "\n",
    "# Hyperparameters for XGBoost algorithm\n",
    "xgboost_params = {\n",
    "    'num_round':100,\n",
    "    'objective': 'reg:linear',\n",
    "    'alpha': l1,\n",
    "    'lambda': l2\n",
    "}\n",
    "\n",
    "# Hyperparameters for LinearLearner algorithm\n",
    "linear_params = {\n",
    "    'feature_dim':len(abalone_data.columns)-1,\n",
    "    'predictor_type': 'regressor',\n",
    "    'loss': 'squared_loss',\n",
    "    'l1': l1,\n",
    "    'wd': l2\n",
    "}\n",
    "\n",
    "hyperparams = {\n",
    "    'linear-learner': linear_params,\n",
    "    'xgboost': xgboost_params\n",
    "}\n",
    "\n",
    "print('All model parameters have been set!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:04:03.337949Z",
     "iopub.status.busy": "2022-03-14T17:04:03.337753Z",
     "iopub.status.idle": "2022-03-14T17:04:03.397772Z",
     "shell.execute_reply": "2022-03-14T17:04:03.397140Z",
     "shell.execute_reply.started": "2022-03-14T17:04:03.337919Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75777b6c16414b139666af3538fba066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The SageMaker model was constructed with parameters: {'num_round': 100, 'objective': 'reg:linear', 'alpha': 0.25, 'lambda': 0.25}."
     ]
    }
   ],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=retrieve(framework=model, region=region, version='latest', py_version='py3'), \n",
    "    role=sagemaker_execution_role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.m5.large',\n",
    "    sagemaker_session=sage_sdk_session, \n",
    "    hyperparameters=hyperparams[model]\n",
    ")\n",
    "\n",
    "print('The SageMaker model was constructed with parameters: {}.'.format(estimator.hyperparameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we initialized the model, we can train the model by calling the fit() function. After calling fit(), SageMaker will create a training instance, train a model on the instance, save the model artifacts to S3, then take down the training instance.\n",
    "\n",
    "This usually takes about 3 minutes. \n",
    "\n",
    "(**Optional**) While you wait, you may check the model training progress through the SageMaker console by following these instructions:  \n",
    "a.\tOpen SageMaker console in AWS.  \n",
    "b.\tOn the left panel, scroll until you see ‘training jobs’ beneath the ‘Training’ section.  \n",
    "c.\tClick into the job to examine further details; wait until you see the status change to ‘Completed’.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:19:55.269638Z",
     "iopub.status.busy": "2022-03-14T17:19:55.269440Z",
     "iopub.status.idle": "2022-03-14T17:23:09.138069Z",
     "shell.execute_reply": "2022-03-14T17:23:09.137388Z",
     "shell.execute_reply.started": "2022-03-14T17:19:55.269609Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab13689193dc422299b4ea3189ba79f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-14 17:19:55 Starting - Starting the training job...\n",
      "2022-03-14 17:20:22 Starting - Preparing the instances for training.........\n",
      "2022-03-14 17:21:35 Downloading - Downloading input data...\n",
      "2022-03-14 17:22:26 Training - Downloading the training image.Arguments: train\n",
      "[2022-03-14:17:22:29:INFO] Running standalone xgboost training.\n",
      "[2022-03-14:17:22:29:INFO] Path /opt/ml/input/data/validation does not exist!\n",
      "[2022-03-14:17:22:29:INFO] File size need to be processed in the node: 0.11mb. Available memory size in the node: 320.92mb\n",
      "[2022-03-14:17:22:29:INFO] Determined delimiter of CSV input is ','\n",
      "[17:22:29] S3DistributionType set as FullyReplicated\n",
      "[17:22:29] 3085x7 matrix with 21595 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[0]#011train-rmse:7.19716\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[1]#011train-rmse:5.31388\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[2]#011train-rmse:4.06916\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[3]#011train-rmse:3.27328\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[4]#011train-rmse:2.77623\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 116 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[5]#011train-rmse:2.48897\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 118 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[6]#011train-rmse:2.31437\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[7]#011train-rmse:2.20255\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[8]#011train-rmse:2.13577\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[9]#011train-rmse:2.0853\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[10]#011train-rmse:2.04906\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[11]#011train-rmse:2.02847\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[12]#011train-rmse:1.99371\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[13]#011train-rmse:1.96833\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[14]#011train-rmse:1.95515\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[15]#011train-rmse:1.94081\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[16]#011train-rmse:1.90827\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[17]#011train-rmse:1.88544\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[18]#011train-rmse:1.84968\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[19]#011train-rmse:1.83084\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 100 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[20]#011train-rmse:1.82303\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[21]#011train-rmse:1.81668\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[22]#011train-rmse:1.79276\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[23]#011train-rmse:1.77629\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[24]#011train-rmse:1.76759\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[25]#011train-rmse:1.74207\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[26]#011train-rmse:1.71592\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[27]#011train-rmse:1.6918\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[28]#011train-rmse:1.68714\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[29]#011train-rmse:1.68366\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[30]#011train-rmse:1.67426\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[31]#011train-rmse:1.65933\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[32]#011train-rmse:1.63951\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[33]#011train-rmse:1.6239\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[34]#011train-rmse:1.60843\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[35]#011train-rmse:1.59912\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[36]#011train-rmse:1.5853\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[37]#011train-rmse:1.56397\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 108 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[38]#011train-rmse:1.52904\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[39]#011train-rmse:1.51432\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[40]#011train-rmse:1.49663\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[41]#011train-rmse:1.49399\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[42]#011train-rmse:1.47426\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[43]#011train-rmse:1.46033\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[44]#011train-rmse:1.44882\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[45]#011train-rmse:1.44549\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[46]#011train-rmse:1.43411\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[47]#011train-rmse:1.42774\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[48]#011train-rmse:1.41689\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[49]#011train-rmse:1.40324\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 92 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[50]#011train-rmse:1.39005\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[51]#011train-rmse:1.378\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[52]#011train-rmse:1.35954\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[53]#011train-rmse:1.35461\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 64 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[54]#011train-rmse:1.34373\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 102 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[55]#011train-rmse:1.32523\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[56]#011train-rmse:1.31453\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[57]#011train-rmse:1.30561\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[58]#011train-rmse:1.30394\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 96 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[59]#011train-rmse:1.29713\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[60]#011train-rmse:1.29146\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[61]#011train-rmse:1.28382\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[62]#011train-rmse:1.27614\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 104 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[63]#011train-rmse:1.26035\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[64]#011train-rmse:1.25484\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 110 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[65]#011train-rmse:1.24092\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[66]#011train-rmse:1.23296\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[67]#011train-rmse:1.22588\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[68]#011train-rmse:1.20823\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[69]#011train-rmse:1.20534\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 74 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[70]#011train-rmse:1.19812\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 66 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[71]#011train-rmse:1.19036\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[72]#011train-rmse:1.18637\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 82 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[73]#011train-rmse:1.17573\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[74]#011train-rmse:1.16315\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 106 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[75]#011train-rmse:1.1468\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[76]#011train-rmse:1.13196\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[77]#011train-rmse:1.12253\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 90 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[78]#011train-rmse:1.11109\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[79]#011train-rmse:1.10436\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 70 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[80]#011train-rmse:1.09672\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 76 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[81]#011train-rmse:1.0926\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[82]#011train-rmse:1.08804\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 98 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[83]#011train-rmse:1.08002\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 84 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[84]#011train-rmse:1.07663\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[85]#011train-rmse:1.07077\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 78 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[86]#011train-rmse:1.06006\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[87]#011train-rmse:1.04983\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 60 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[88]#011train-rmse:1.04247\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[89]#011train-rmse:1.0418\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[90]#011train-rmse:1.04055\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[91]#011train-rmse:1.03651\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[92]#011train-rmse:1.02842\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 80 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[93]#011train-rmse:1.0233\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[94]#011train-rmse:1.01719\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 94 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[95]#011train-rmse:1.00304\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 88 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[96]#011train-rmse:0.999457\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 68 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[97]#011train-rmse:0.997802\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 72 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[98]#011train-rmse:0.99653\n",
      "[17:22:29] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 0 pruned nodes, max_depth=6\n",
      "[99]#011train-rmse:0.991281\n",
      "\n",
      "2022-03-14 17:22:42 Uploading - Uploading generated training model\n",
      "2022-03-14 17:22:42 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67"
     ]
    }
   ],
   "source": [
    "train_channel = sagemaker.session.s3_input(s3_train + 'part', content_type='text/csv')\n",
    "estimator.fit({'train': train_channel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did our model perform? Let's see how it does on the test data set we saved to S3 earlier. We'll use [SageMaker batch transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html) to run our test data set through our model. Batch transform creates a SageMaker instance, deploys the model, runs the dataset through the model, then takes down the instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:11:09.596694Z",
     "iopub.status.busy": "2022-03-14T17:11:09.596441Z",
     "iopub.status.idle": "2022-03-14T17:11:10.362197Z",
     "shell.execute_reply": "2022-03-14T17:11:10.361488Z",
     "shell.execute_reply.started": "2022-03-14T17:11:09.596664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1f346d19914a90ac867b7e3611ce45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker batch transform initialized with the following parameters:\n",
      "model_name:xgboost-2022-03-14-17-11-09-634\n",
      "strategy:MultiRecord\n",
      "env:None\n",
      "output_path:s3://sagemaker-us-east-1-620614497509/inference/\n",
      "output_kms_key:None\n",
      "accept:text/csv\n",
      "assemble_with:Line\n",
      "instance_count:1\n",
      "instance_type:ml.m5.large\n",
      "volume_kms_key:None\n",
      "max_concurrent_transforms:None\n",
      "max_payload:None\n",
      "tags:None\n",
      "base_transform_job_name:xgboost\n",
      "_current_job_name:None\n",
      "latest_transform_job:None\n",
      "_reset_output_path:False\n",
      "sagemaker_session:<sagemaker.session.Session object at 0x7f74af60ed50>"
     ]
    }
   ],
   "source": [
    "s3_inference = s3_train.replace('train', 'inference')\n",
    "\n",
    "transformer = estimator.transformer(\n",
    "    instance_count = 1,\n",
    "    instance_type = 'ml.m5.large',\n",
    "    strategy = 'MultiRecord',\n",
    "    output_path = s3_inference,\n",
    "    assemble_with= 'Line',\n",
    "    accept=('text/'+data_format)\n",
    ")\n",
    "\n",
    "print('SageMaker batch transform initialized with the following parameters:')\n",
    "for key in transformer.__dict__:\n",
    "    print('{}:{}'.format(key, transformer.__dict__[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform() function initiates the SageMaker batch transform job. SageMaker will create an inference instance, run the specified test set through the model, save the results to S3, and take down the inference instance. Batch transform is a great option if you require inference for large datasets and don't need sub-second response time.\n",
    "\n",
    "This usually takes 3 minutes. \n",
    "\n",
    "(**Optional**) While you wait, you may check the batch transform progress through the SageMaker console by following these instructions:  \n",
    "a.\tOpen SageMaker console in AWS.  \n",
    "b.\tOn the left panel, scroll until you see ‘Batch transform jobs’ beneath the ‘Inference’ section.  \n",
    "c.\tClick into the job to examine further details; wait until you see the status change to ‘Completed’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:11:14.434723Z",
     "iopub.status.busy": "2022-03-14T17:11:14.434462Z",
     "iopub.status.idle": "2022-03-14T17:16:30.715066Z",
     "shell.execute_reply": "2022-03-14T17:16:30.714381Z",
     "shell.execute_reply.started": "2022-03-14T17:11:14.434693Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6068dd2b01f14913b0db0d758e9111bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................Arguments: serve\n",
      "[2022-03-14 17:15:47 +0000] [1] [INFO] Starting gunicorn 19.9.0\n",
      "[2022-03-14 17:15:47 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\n",
      "[2022-03-14 17:15:47 +0000] [1] [INFO] Using worker: gevent\n",
      "[2022-03-14 17:15:47 +0000] [21] [INFO] Booting worker with pid: 21\n",
      "[2022-03-14 17:15:47 +0000] [22] [INFO] Booting worker with pid: 22\n",
      "/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\n",
      "[2022-03-14:17:15:47:INFO] Model loaded successfully for worker : 21\n",
      "/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\n",
      "[2022-03-14:17:15:47:INFO] Model loaded successfully for worker : 22\n",
      "[2022-03-14:17:15:51:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:51:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:51:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:51:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "[2022-03-14:17:15:52:INFO] Sniff delimiter as ','\n",
      "[2022-03-14:17:15:52:INFO] Determined delimiter of CSV input is ','\n",
      "2022-03-14T17:15:51.626:[sagemaker logs]: MaxConcurrentTransforms=2, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD"
     ]
    }
   ],
   "source": [
    "# The test data set still contains the \"Rings\" column the model tries to predict. \n",
    "# We do not want to send this column to the model, though. We use the SageMaker\n",
    "# input_filter to filter out that column before sending to the model. We then\n",
    "# join the model output with the input so we can compare the actual Rings count\n",
    "# to the predicted count.\n",
    "transformer.transform(\n",
    "    data=s3_test,\n",
    "    content_type='text/csv',\n",
    "    split_type='Line',\n",
    "    input_filter='$[1:]',\n",
    "    join_source='Input',\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMaker batch transform completed and saved the model inference results to S3. Now let's pull the results in to Spark for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:16:30.716355Z",
     "iopub.status.busy": "2022-03-14T17:16:30.716158Z",
     "iopub.status.idle": "2022-03-14T17:16:40.012940Z",
     "shell.execute_reply": "2022-03-14T17:16:40.012384Z",
     "shell.execute_reply.started": "2022-03-14T17:16:30.716326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76278268b79d46b29662a56c33e89aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+--------+------+----+------+------+-----------------+---------------+\n",
      "|Rings|Length|Diameter|Height|Male|Female|Infant|Difference_weight|Estimated_rings|\n",
      "+-----+------+--------+------+----+------+------+-----------------+---------------+\n",
      "|    9|  0.34|   0.255| 0.095|   1|     0|     0|            0.143|       8.482176|\n",
      "|    8| 0.585|    0.45|  0.15|   0|     0|     1|           0.6385|       8.534326|\n",
      "|    5| 0.255|    0.19|  0.07|   0|     0|     1|           0.0505|      5.6782026|\n",
      "|    9| 0.565|    0.44| 0.135|   0|     0|     1|           0.5205|       8.723779|\n",
      "|   10| 0.575|    0.45| 0.135|   0|     1|     0|           0.5925|       10.79155|\n",
      "+-----+------+--------+------+----+------+------+-----------------+---------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Read the schema from the initial dataset so you can apply it to the inference data.\n",
    "schema = deepcopy(abalone_data.schema)\n",
    "schema.add(\"Estimated_rings\", FloatType())\n",
    "\n",
    "# Pull down the inference data from S3\n",
    "inference_data = spark.read.load(s3_inference, format=data_format, schema=schema).repartition(num_workers)\n",
    "inference_data.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our results, we need to quantify our model's performance. We will use root mean square error (RMSE) to measure how close Estimated_rings is to the actual Rings value.\n",
    "\n",
    "RMSE is a popular way to measure how closely a regression model predicts a response. A lower RMSE indicates a closer prediction.\n",
    "\n",
    "Here is the equation for RMSE:\n",
    "\n",
    "\\begin{equation*}\n",
    "RMSE = \\sqrt{\\frac{\\sum_{i=1}^n (\\hat{y_i}-y_i)^2}{N}}\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\hat{y_i}$ is the number of predicted rings, $y_i$ is the observed number of rings, and N is the number of rows in the test data set.\n",
    "\n",
    "We'll use Spark SQL to run a SQL query on our data to calculate the RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-14T17:30:21.339540Z",
     "iopub.status.busy": "2022-03-14T17:30:21.339256Z",
     "iopub.status.idle": "2022-03-14T17:30:30.634288Z",
     "shell.execute_reply": "2022-03-14T17:30:30.633505Z",
     "shell.execute_reply.started": "2022-03-14T17:30:21.339509Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a39df746fe0427fb2592aa0d450474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             RMSE|\n",
      "+-----------------+\n",
      "|2.810150564902427|\n",
      "+-----------------+"
     ]
    }
   ],
   "source": [
    "rings = inference_data.schema.names[0]\n",
    "predicted_rings = inference_data.schema.names[-1]\n",
    "table_name = 'inference'\n",
    "\n",
    "inference_data.registerTempTable(table_name)\n",
    "sql_rmse = 'SELECT SQRT(AVG(POWER({}-{}, 2))) AS RMSE FROM {}'.format(rings, predicted_rings, table_name)\n",
    "\n",
    "rmse_results = spark.sql(sql_rmse)\n",
    "rmse_results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "Congratulations! You processed data in Apache Spark on EMR and trained and deployed a machine learning model in Amazon SageMaker! Feel free to try different combinations of models and hyperparameters to see if you can reduce your model's RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
